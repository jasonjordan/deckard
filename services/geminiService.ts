
import { GoogleGenAI, Type, Modality } from "@google/genai";

const API_KEY = process.env.API_KEY;

if (!API_KEY) {
  throw new Error("API_KEY environment variable not set");
}

const ai = new GoogleGenAI({ apiKey: API_KEY });

interface CommandResponse {
  description: string;
  screen_image_prompt: string;
}

export async function generateScreenFromCommand(command: string, currentScreenDescription: string): Promise<{ description: string; imageUrl: string }> {
  try {
    // Step 1: Generate a description of the action and a prompt for the new screen image.
    const textModel = "gemini-2.5-flash";
    const textPrompt = `
      You are an AI assistant simulating an Android phone interface.
      The user will give you a command to execute.
      The current screen is described as: "${currentScreenDescription}".
      The user's command is: "${command}".

      Based on the command and current screen, decide what the new screen should look like.

      Respond ONLY with a valid JSON object with two keys:
      1. "description": A short, past-tense sentence describing the action taken. Example: "Opened the settings app." or "Navigated to the Wi-Fi settings."
      2. "screen_image_prompt": A detailed, photorealistic prompt for an image generation model to create the new phone screen. Be very specific about UI elements, icons, text, colors, and layout. Assume a modern Android interface. Example: "A smartphone screen showing the main settings menu on a light theme. A list of options includes 'Network & internet', 'Connected devices', 'Apps', and 'Notifications'. A search bar is at the top. The navigation bar is at the bottom."
    `;

    const textGenerationResponse = await ai.models.generateContent({
      model: textModel,
      contents: textPrompt,
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            description: { type: Type.STRING },
            screen_image_prompt: { type: Type.STRING },
          },
          required: ["description", "screen_image_prompt"]
        }
      }
    });

    const responseJsonText = textGenerationResponse.text.trim();
    const commandResponse: CommandResponse = JSON.parse(responseJsonText);
    
    // Step 2: Generate the image based on the new prompt.
    const imageModel = 'gemini-2.5-flash-image';
    const imageGenerationResponse = await ai.models.generateContent({
        model: imageModel,
        contents: {
            parts: [{ text: commandResponse.screen_image_prompt }],
        },
        config: {
            responseModalities: [Modality.IMAGE],
        },
    });

    let imageUrl = '';
    const firstPart = imageGenerationResponse.candidates?.[0]?.content?.parts?.[0];
    if (firstPart && 'inlineData' in firstPart && firstPart.inlineData) {
        const base64ImageBytes: string = firstPart.inlineData.data;
        imageUrl = `data:${firstPart.inlineData.mimeType};base64,${base64ImageBytes}`;
    } else {
        throw new Error("No image was generated by the API.");
    }
    
    return {
      description: commandResponse.description,
      imageUrl: imageUrl,
    };

  } catch (error) {
    console.error("Error in Gemini service:", error);
    throw new Error("Failed to process command with Gemini API.");
  }
}
